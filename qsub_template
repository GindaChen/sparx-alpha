#!/bin/bash
###### Job name ######
#PBS -N SPARX
###### Output files ######
#PBS -e SPARX.err
#PBS -o SPARX.log
###### Queue name #######
#PBS -q large
###### Number of nodes and cores ######
#PBS -l nodes=20:ppn=12
###### Sends mail to yourself when the job begins and ends ######
#PBS -M ithsieh@asiaa.sinica.edu.tw
#PBS -m be
###### Specific the shell types ######
#PBS -S /bin/bash

PBS_O_WORKDIR=~/test
mkdir -p $PBS_O_WORKDIR

###### Enter this job's working directory ######
cd $PBS_O_WORKDIR

###### Load modules to setup environment ######
source ~/.load_sparx_module


###### Run parallel jobs ######
 
if [ -n "$PBS_NODEFILE" ]; then
  if [ -f $PBS_NODEFILE ]; then
    awk '!x[$0]++' $PBS_NODEFILE > MPIHOST
  fi
fi

NPROCS=`wc -l < MPIHOST`


rm -rf pops* history.log

CLUSTERNAME=${HOSTNAME:0:2}
sparx_version=`which sparx-$CLUSTERNAME`

$OPENMPI_HOME/bin/mpirun -v -machinefile MPIHOSTE -np $NPROCS \
$sparx_version --parallel run task_amc \
source=model \
out=pops \
molec='co_21lev' \
trace='True' \
lte='True' \
tolerance=5e-3 \
snr=20 \
raniter=2 \
fixiter=2 \
| tee history.log

rm -rf MPIHOST
