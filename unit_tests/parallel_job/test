#!/bin/bash
###### Job name ######
#PBS -N SPARX
###### Output files ######
#PBS -o SPARX.out
#PBS -e SPARX.err
###### Number of nodes and cores ######
#PBS -l nodes=4:ppn=8
###### Queue name ######
#PBS -q small
###### Specific the shell types ######
#PBS -S /bin/bash

###### Enter this job's working directory ######

PBS_O_WORKDIR=/lustre/home/ydhsieh/alma_2016_disk_polariz
mkdir -p $PBS_O_WORKDIR
cd $PBS_O_WORKDIR

###### Load modules to setup environment ######
source ~/.load_sparx_module


rm -rf pops* history.log 

# for LAM
awk '!x[$0]++' $PBS_NODEFILE > LAMHOST
$LAM_HOME/bin/lamboot LAMHOST
$LAM_HOME/bin/mpiexec C sparx --parallel run task_amc source=$model out=pops_$case molec=$molecule trace='True' lte='True' tolerance=5e-3 snr=20 minpop=1e-6 nrays=1000 maxiter=20 raniter=1 fixiter=1 | tee history.log
$LAM_HOME/bin/lamhalt
rm -rf LAMHOST

# OPENMPI
###### Run your jobs with parameters ######
if [ -n "$PBS_NODEFILE" ]; then
  if [ -f $PBS_NODEFILE ]; then
    awk '!x[$0]++' $PBS_NODEFILE > OPENMPI_HOST
    NPROCS=`wc -l < OPENMPI_HOST`
  fi
fi
rm -f OPENMPI_HOST
$OPENMPI_HOME/bin/mpirun -v -machinefile $PBS_NODEFILE -np $NPROCS ./ 
